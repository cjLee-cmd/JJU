import chromadb
import numpy as np
from sentence_transformers import SentenceTransformer

# ğŸ”„ ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
chroma_client = chromadb.PersistentClient(path="./chroma_db")

# ğŸ”„ ì‚¬ìš© ëª¨ë¸ (384ì°¨ì› ì¶œë ¥ ëª¨ë¸)
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")  # ì°¨ì›: 384

def reset_chroma_collection():
    """ê¸°ì¡´ ChromaDB ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±"""
    try:
        chroma_client.delete_collection(name="document_embeddings")
        print("ğŸ”„ ê¸°ì¡´ ChromaDB ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ!")
    except Exception as e:
        print(f"âš ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    collection = chroma_client.create_collection(name="document_embeddings", metadata={"dimension": 384})
    print("âœ… ìƒˆë¡œìš´ ChromaDB ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ (dim=384)!")
    return collection

def generate_embeddings(document_chunks):
    """ë¬¸ì„œ ì¡°ê° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì„ë² ë”© ë²¡í„° ìƒì„±"""
    print(f"ğŸ“Œ ë¬¸ì„œ ì¡°ê° ìˆ˜: {len(document_chunks)}")
    embeddings = embedding_model.encode(document_chunks, convert_to_numpy=True)
    print(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ! (ì°¨ì›: {embeddings.shape})")
    return embeddings

def save_embeddings_to_chromadb(embeddings, document_chunks):
    """ìƒì„±ëœ ì„ë² ë”©ì„ ChromaDBì— ì €ì¥ (384ì°¨ì› ê³ ì •)"""
    collection = reset_chroma_collection()
    for i, (embedding, text) in enumerate(zip(embeddings, document_chunks)):
        if len(embedding) != 384:
            print(f"âš ï¸ ê²½ê³ : ì„ë² ë”© ë²¡í„° ì°¨ì›ì´ {len(embedding)}ì…ë‹ˆë‹¤. 384ë¡œ ë³€í™˜ í•„ìš”!")
            continue
        collection.add(
            ids=[f"doc_{i}"],
            embeddings=[embedding.tolist()],
            metadatas=[{"text": text}]
        )
    print("âœ… ChromaDBì— ì„ë² ë”© ì €ì¥ ì™„ë£Œ!")

def find_similar_chunks(query, top_k=3):
    """
    ì£¼ì–´ì§„ ì§ˆë¬¸(query)ì— ëŒ€í•´ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ì¡°ê°ì„ ChromaDBì—ì„œ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜.
    """
    collection = chroma_client.get_collection(name="document_embeddings")
    
    # ì§ˆë¬¸(query)ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (queryëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•¨)
    query_embedding = embedding_model.encode([query])[0]  # query ë³€ìˆ˜ ì‚¬ìš©

    results = collection.query(
        query_embeddings=[query_embedding.tolist()],
        n_results=top_k
    )

    similar_docs = []
    for idx, doc_id in enumerate(results["ids"][0]):
        doc_text = collection.get([doc_id])["metadatas"][0]["text"]
        similarity_score = results["distances"][0][idx]
        similar_docs.append((doc_text, similarity_score))

    print(f"âœ… ìœ ì‚¬í•œ ë¬¸ì„œ {top_k}ê°œ ê²€ìƒ‰ ì™„ë£Œ!")
    return similar_docs